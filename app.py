# -*- coding: utf-8 -*-
"""
PDF Chatbot - ÙˆØ§Ø¬Ù‡Ø© Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø¬Ø¯Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit + LangChain + Google GenAI
"""

import os
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from dotenv import load_dotenv
import streamlit as st

# ==========================
# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
# ==========================
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
if not GOOGLE_API_KEY:
    st.error("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ ÙˆØ¶Ø¹ GOOGLE_API_KEY ÙÙŠ Ù…Ù„Ù .env")
    st.stop()

# ==========================
# Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØ§Ø¬Ù‡Ø© Streamlit
# ==========================
st.set_page_config(page_title="ğŸ“„ PDF Chatbot", layout="wide")


st.markdown("""
<style>
body {
    background-color: #f7f7f8;
}
.chat-container {
    max-width: 900px;
    margin: auto;
    padding: 10px;
}
.user-msg {
    background-color: #DCF8C6;
    padding: 12px 18px;
    border-radius: 20px;
    margin: 5px 0;
    text-align: right;
    font-size: 16px;
    color: #000000;
}
.bot-msg {
    background-color: #FFFFFF;
    padding: 12px 18px;
    border-radius: 20px;
    margin: 5px 0;
    text-align: left;
    font-size: 16px;
    box-shadow: 0px 1px 3px rgba(0,0,0,0.1);
    color: #000000; 
}
.bot-icon {
    width: 30px;
    vertical-align: middle;
    margin-right: 8px;
}
.user-icon {
    width: 30px;
    vertical-align: middle;
    margin-left: 8px;
}
</style>
""", unsafe_allow_html=True)


st.title("ğŸ“„ PDF Chatbot")
st.markdown("Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF ÙˆØ§Ø¨Ø¯Ø£ Ù…Ø­Ø§Ø¯Ø«Ø© ØªÙØ§Ø¹Ù„ÙŠØ©  !")

# ==========================
# Ø±ÙØ¹ PDF
# ==========================
uploaded_file = st.file_uploader("Ø§Ø®ØªØ± Ù…Ù„Ù PDF", type="pdf")

if uploaded_file is not None:

    # ==========================
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
    # ==========================
    pdf_reader = PdfReader(uploaded_file)
    text = ""
    for page in pdf_reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text

    if not text.strip():
        st.error("âŒ Ø§Ù„Ù…Ù„Ù Ù„Ø§ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†Øµ Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø©.")
        st.stop()

    # ==========================
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ù€ separators Ø§Ù„Ù‡Ø±Ù…ÙŠ
    # ==========================
    text_splitter = RecursiveCharacterTextSplitter(
        separators=["\n\n", "\n", ".", " ", ""],
        chunk_size=500,
        chunk_overlap=50,
        length_function=len
    )
    chunks = text_splitter.split_text(text)
    st.success(f"âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ {len(chunks)} chunks")

    # ==========================
    # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
    # ==========================
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    knowledge_base = FAISS.from_texts(chunks, embeddings)

    # ==========================
    # Ø¥Ø¹Ø¯Ø§Ø¯ LLM ÙˆØ°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    # ==========================
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        google_api_key=GOOGLE_API_KEY,
        temperature=0.2
    )
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
    qa_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=knowledge_base.as_retriever(),
        memory=memory
    )

    # ==========================
    # Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    # ==========================
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    user_input = st.text_input("ğŸ’¬ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§:")

    if user_input:
        response = qa_chain({"question": user_input})
        # Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
        st.session_state.chat_history.append({"user": user_input, "bot": response["answer"]})

    # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø¨Ø´ÙƒÙ„ ÙÙ‚Ø§Ø¹Ø§Øª Ù…Ø«Ù„ ChatGPT
    st.markdown('<div class="chat-container">', unsafe_allow_html=True)
    for chat in st.session_state.chat_history:
        st.markdown(f'<div class="user-msg">ğŸ§‘ {chat["user"]}</div>', unsafe_allow_html=True)
        st.markdown(f'<div class="bot-msg">ğŸ¤– {chat["bot"]}</div>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)

st.markdown("---")

